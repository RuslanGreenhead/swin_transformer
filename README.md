# Swin Transformer

This project is an implementation of the paper **"Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"**. The Swin Transformer serves as a general-purpose backbone for computer vision tasks, effectively addressing the challenges of adapting Transformer models from language to vision.

### Model Architecture:

![Swin Transformer Architecture](https://amaarora.github.io/images/swin-transformer.png)

### Repo structure:

 ```
ðŸ“¦swin_transformer
 â”£ ðŸ“‚experiments
 â”ƒ â”— ðŸ“‚experiment_0                        # Swin-T -> single testing epoch
 â”ƒ â”— ðŸ“‚experiment_1                        # Swin-T -> training over 30 epochs (2 GPU)
 â”ƒ â”— ðŸ“‚experiment_2                        # Swin-T -> training over 10 epochs (2 GPU)
 â”ƒ â”— ðŸ“‚experiment_3                        # Swin-T -> training over 50 epochs (same setup as experiment_2)
 â”ƒ â”— ðŸ“‚experiment_4                        # Swin-T -> full-scale training (300(20 - warmup) epochs) (2 GPU)
 â”ƒ 
 â”£ ðŸ“‚notebooks
 â”ƒ â”£ ðŸ“œImageNet_classification.ipynb       # debugging ImageNet proceeding
 â”ƒ â”— ðŸ“œplayground.ipynb                    # notebook with scetching & testing the modules 
 â”ƒ
 â”£ ðŸ“œmodel.py                              # all the building blocks of the network
 â”£ ðŸ“œdata.py                               # data processing issues
 â”£ ðŸ“œtraining.py                           # training code -> ImageNet 1K [classification]
 â”£ ðŸ“œtrain_clf_ddp.sbatch                  # cluster task -> ImageNet 1K [classification]
 â”— ðŸ“œ__init__.py
 ```

### Links & Sources:

* [Original paper](https://arxiv.org/abs/2103.14030)
* [Official implementation by Microsoft](https://github.com/microsoft/Swin-Transformer)