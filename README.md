# Swin Transformer

This project is an implementation of the paper **"Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"**. The Swin Transformer serves as a general-purpose backbone for computer vision tasks, effectively addressing the challenges of adapting Transformer models from language to vision.

*(All experiments were done on the Higher School of Economics HPC cluster ['cHARISMa'](https://hpc.hse.ru/hardware/hpc-cluster/) ‚Äî big thanks to the team!)*

### Model Architecture:

![Swin Transformer Architecture](https://amaarora.github.io/images/swin-transformer.png)

---
### Classification:
The Swin Transformer model (SwinT variant) was pretrained on the ImageNet-1k dataset for the classification task. Training logs and detailed experiment results can be found in *experiments/experiment_1*. The achieved accuracy closely matches the results reported in the [original paper](https://arxiv.org/abs/2103.14030):

| model               | accuracy@1 | accuracy@5|
|---------------------|------------|-----------|
| SwinT  (~28M params)|   0.8060   |  0.9510   |

---

### Detection:
For the detection task, conducted on the Microsoft COCO dataset, an SSD framework was implemented. Several Swin-based backbones were designed alongside reference ResNet-based backbones. The SSD detector was evaluated with different backbones and neck variants‚Äîtwo well-known and one newly proposed. The architectures of the proposed backbone networks are illustrated below:

<p align="left"> <img src="imgs/mutual_scheme.jpg" alt="ResNet50 backbones" /> </p>

The key detection results are summarized in the table below. The metric reported is the *COCO mean Average Precision (COCO_mAP)*, calculated over IoU thresholds ranging from 0.5 to 0.95 with 11 evaluation points:

| necks‚ñ∂<br>backbones‚ñº  | no neck  |     FPN      |    PAN   |   DenseFPN   |
|-----------------------|----------|--------------|----------|--------------|
| ResNet50Backbone_A    | 0.228332 |    --        |   --     |     --       |
| ResNet50Backbone_B    | 0.247096 | 0.250236     | 0.252202 | **0.253052** |
| SwinTBackbone_A       | 0.164175 |     --       |    --    |     --       |
| SwinTBackbone_B       | 0.258104 | **0.259176** | 0.258641 |   0.256729   |

Noteworthy: training with Swin backbones is ~1h faster (~6.5 hours versus ~7.5 hours) 
---

### Diffusion generation:
-- in progress 

---

### Repo structure:

 ```
üì¶swin_transformer
 ‚î£ üìÇconfigs                          # training configurations
 ‚îÉ ‚î£ üìúSwinT_clf_300e_default.yaml
 ‚îÉ ‚î£ üìúdetection_ssd_SwinT.yaml
 ‚îÉ ‚î£ üìúdetection_ssd_resnet50.yaml
 ‚îÉ ‚îó üìúdiffusion_unet_SwinT.yaml
 ‚îÉ 
 ‚î£ üìÇdetection
 ‚îÉ ‚î£ üìúbackbones.py
 ‚îÉ ‚î£ üìúdata.py
 ‚îÉ ‚î£ üìúnecks.py
 ‚îÉ ‚î£ üìússd.py
 ‚îÉ ‚î£ üìútest.py                        # source for full validation pipeline
 ‚îÉ ‚î£ ‚öôÔ∏ètest_detection.sbatch          # slurm script -> test.py (no DDP)
 ‚îÉ ‚î£ ‚öôÔ∏ètrain_det_ddp.sbatch           # slurm script -> training.py (DDP)
 ‚îÉ ‚î£ üìútraining.py                    # source for training
 ‚îÉ ‚îó üìúutils.py
 ‚îÉ
 ‚î£ üìÇdiffusion
 ‚îÉ ‚î£ üìúdata.py
 ‚îÉ ‚î£ üìúdiffusion_model.py
 ‚îÉ ‚î£ üìúschedulers.py
 ‚îÉ ‚î£ ‚öôÔ∏ètrain_diff_ddp.sbatch          # slurm script -> training.py (DDP)
 ‚îÉ ‚îó üìútraining.py                    # source for training
 ‚îÉ 
 ‚î£ üìÇexperiments
 ‚îÉ ‚î£ üìÇexperiment_0                   # trial run
 ‚îÉ ‚î£ üìÇexperiment_1                   # ImageNet classification -> SwinT
 ‚îÉ ‚îÉ
 ‚îÉ ‚î£ üìÇexperiment_2                   # SSD detection -> ResNet (B)
 ‚îÉ ‚î£ üìÇexperiment_3                   # SSD detection -> ResNet (B) + FPN
 ‚îÉ ‚î£ üìÇexperiment_4                   # SSD detection -> ResNet (B) + PAN
 ‚îÉ ‚î£ üìÇexperiment_5                   # SSD detection -> ResNet (B) + DenseFPN
 ‚îÉ ‚î£ üìÇexperiment_6                   # SSD detection -> SwinT (A) (short scheduling)
 ‚îÉ ‚î£ üìÇexperiment_7                   # SSD detection -> SwinT (B) (short scheduling)
 ‚îÉ ‚î£ üìÇexperiment_8                   # SSD detection -> SwinT (B)
 ‚îÉ ‚î£ üìÇexperiment_9                   # SSD detection -> SwinT (B) + FPN  
 ‚îÉ ‚î£ üìÇexperiment_10                  # SSD detection -> SwinT (B) + PAN
 ‚îÉ ‚î£ üìÇexperiment_11                  # SSD detection -> SwinT (B) + DenseFPN
 ‚îÉ ‚îÉ
 ‚îÉ ‚î£ üìÇexperiment_12                  # diffusion -> SwinUNet (CIFAR-10)
 ‚îÉ ‚î£ üìÇexperiment_13                  # diffusion -> SwinUNet (CIFAR-10)
 ‚îÉ ‚îó üìÇexperiment_14                  # diffusion -> SwinUNet (MNIST) 
 ‚îÉ
 ‚î£ üìÇnotebooks                        # some old colab drafts 
 ‚îÉ ‚î£ üìúImageNet_classification.ipynb
 ‚îÉ ‚îó üìúplayground.ipynb
 ‚îÉ
 ‚î£ üìÇsaved_weights
 ‚îÉ ‚î£ üì¶SwinT_statedict.pth            # stored locally 
 ‚îÉ ‚îó üì¶resnet50_statedict.pth         # stored locally
 ‚îÉ
 ‚î£ üìúdata.py
 ‚î£ üìúmodel.py                         # Swin Transformer implementation
 ‚î£ ‚öôÔ∏ètrain_clf_ddp.sbatch.            # slurm script -> training.py (DDP)
 ‚î£ ‚öôÔ∏ètrain_clf_default.sbatch
 ‚î£ üìútrain_clf_imagenet.py
 ‚îó üìútraining.py                      # source for classification training
 ```

### References & Useful sources:

* [Original Swin paper](https://arxiv.org/abs/2103.14030)
* [Official Swin implementation by Microsoft](https://github.com/microsoft/Swin-Transformer)
* [Original SSD paper](https://arxiv.org/abs/1512.02325)
* [Very good SSD tutorial](https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/tree/master)